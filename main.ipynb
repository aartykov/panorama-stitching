{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtu6rMDfBU0y"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "def normalize_points(img):\n",
        "  \"\"\"\n",
        "  input: img(N, 2) N number of points in 1 image\n",
        "\n",
        "  outputs: img_normalized(N, 3), T(3,3)\n",
        "  \"\"\"\n",
        "\n",
        "  mean, std = np.mean(img, axis=0), np.std(img)\n",
        "\n",
        "  T = np.array([[std/np.sqrt(2), 0, mean[0]],\n",
        "                [0, std/np.sqrt(2), mean[1]],\n",
        "                [0,   0, 1]])\n",
        "\n",
        "  T_inv = np.linalg.inv(T)\n",
        "  img_aug = np.column_stack([img, np.ones(img.shape[0])]).T\n",
        "\n",
        "  img_normalized = T_inv.dot(img_aug).T\n",
        "\n",
        "  return img_normalized, T_inv\n",
        "\n",
        "\n",
        "\n",
        "def skewed(a, b, c):\n",
        "  A = np.zeros((2,9))\n",
        "  A[0, 3:6] = -c\n",
        "  A[0, 6:] = b\n",
        "  A[1, :3] = c\n",
        "  A[1, 6:] = -a\n",
        "  return A  \n",
        "\n",
        "def DLT(pnt_set1, pnt_set2, num_pnts):\n",
        "  \"\"\"\n",
        "  inputs: pnt_set1 (N,3)\n",
        "  \"\"\"\n",
        "  # Create the A(2,9) matrix for each point correspondences\n",
        "  A = []\n",
        "  for i in range(num_pnts):\n",
        "        p1 = pnt_set1[i]\n",
        "        p2 = pnt_set2[i]\n",
        "        p1_transpose = p1.T\n",
        "        c = p2[2] * p1_transpose\n",
        "        b = p2[1] * p1_transpose\n",
        "        a = p2[0] * p1_transpose\n",
        "        A.append(skewed(a, b, c))  # (2, 9)\n",
        "\n",
        "  A = np.concatenate(A, axis=0)\n",
        "  U, D, V = np.linalg.svd(A)\n",
        "  h = V[-1, :] / V[-1, -1]\n",
        "  H = h.reshape(3,3)\n",
        "  #H = np.zeros((3,3))\n",
        "  #H[0, :] = h[:3].T\n",
        "  #H[1, :] = h[3:6].T\n",
        "  #H[2, :] = h[6:].T\n",
        "  \n",
        "  return H\n",
        "\n",
        "\n",
        "def calc_homography(src_pnts, target_pnts, num_pnts=4):\n",
        "  \n",
        "  # Normalize the points through similarity transform\n",
        "  norm_pnts1, T1 = normalize_points(src_pnts)\n",
        "  norm_pnts2, T2 = normalize_points(target_pnts)\n",
        "\n",
        "  #print(norm_pnts1[0])\n",
        "  # Apply Direct Linear Transform (DLT)\n",
        "  normalized_H = DLT(norm_pnts1, norm_pnts2, num_pnts)\n",
        "\n",
        "  # Denormalize the estimated homography\n",
        "  H = np.dot(np.dot(np.linalg.pinv(T2), normalized_H), T1)\n",
        "\n",
        "  return H\n",
        "\n",
        "\n",
        "def read_images(img1_pth, img2_pth, mask1_pth, mask2_pth):\n",
        "  img1 = cv2.imread(img1_pth)\n",
        "  img2 = cv2.imread(img2_pth)\n",
        "\n",
        "  mask1 = cv2.imread(mask1_pth)\n",
        "  mask2 = cv2.imread(mask2_pth)\n",
        "  \n",
        "  outputs = {\"img1\": img1, \"img2\": img2, \"mask1\": mask1, \"mask2\": mask2}\n",
        "  return outputs\n",
        "\n",
        "def detect_and_match_features(inputs, use_mask=False):\n",
        "  img1 = inputs[\"img1\"]\n",
        "  img2 = inputs[\"img2\"]\n",
        "  mask1 = inputs[\"mask1\"]\n",
        "  mask2 = inputs[\"mask2\"]\n",
        "\n",
        "  # Convert images to gray scale format\n",
        "  gray_img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "  gray_img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Detect and Describe features in both images using ORB algorithm\n",
        "  orb = cv2.ORB_create(nfeatures=10000)\n",
        "  if use_mask:\n",
        "        kp1, des1 = orb.detectAndCompute(gray_img1, mask=mask1)\n",
        "        kp2, des2 = orb.detectAndCompute(gray_img2, mask=mask2)\n",
        "  else:\n",
        "        kp1, des1 = orb.detectAndCompute(gray_img1, mask=None)\n",
        "        kp2, des2 = orb.detectAndCompute(gray_img2, mask=None)\n",
        "\n",
        "  # Match the features by using Flann method\n",
        "  index_params = dict(algorithm=6,\n",
        "                        table_number=6,\n",
        "                        key_size=12,\n",
        "                        multi_probe_level=2)\n",
        "  search_params = {}\n",
        "  flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "  matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "  # According to the Lowe's ratio, test to filter good matches\n",
        "  good_matches = []\n",
        "  for m, n in matches:\n",
        "        if m.distance < 0.75 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "  src_points = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 2)\n",
        "  target_points = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 2)\n",
        "\n",
        "  return src_points, target_points\n",
        "\n",
        "def ransac(src_points, target_points, params):\n",
        "  # Find homography with RANSAC\n",
        "  num_iter = params[\"num_iter\"]\n",
        "  epsilon = params[\"epsilon\"]\n",
        "  threshold = params[\"threshold\"]\n",
        "  num_pnts = params[\"num_pnts\"]\n",
        "  \n",
        "  best_inliers1 = []\n",
        "  best_inliers2 = []\n",
        "  index = np.arange(0, src_points.shape[0])\n",
        "  for i in range(num_iter):\n",
        "        #np.random.shuffle(index)\n",
        "        rand_idx = np.random.choice(index, num_pnts, replace=False)\n",
        "        p1_set = src_points[rand_idx, :] # (num_pnts, 2) np array\n",
        "        p2_set = target_points[rand_idx, :] # (num_pnts, 2) np array\n",
        "        H = calc_homography(p1_set, p2_set, num_pnts)\n",
        "        inliers1 = []\n",
        "        inliers2 = []\n",
        "        for i in range(src_points.shape[0]):\n",
        "          p1 = np.expand_dims(src_points[i, :], 0)\n",
        "          p2 = np.expand_dims(target_points[i, :], 0)\n",
        "          p1_aug = np.column_stack([p1, np.ones((1,1))]).T\n",
        "          p2_aug = np.column_stack([p2, np.ones((1,1))]).T\n",
        "          distance = (np.linalg.norm(p2_aug - H.dot(p1_aug)))**2\n",
        "          if distance <= epsilon:\n",
        "            inliers1.append(p1)\n",
        "            inliers2.append(p2)\n",
        "        \n",
        "        if len(inliers1) > len(best_inliers1):\n",
        "          best_inliers1 = inliers1\n",
        "          best_inliers2 = inliers2\n",
        "          if len(best_inliers1)/src_points.shape[0] > threshold:\n",
        "                  print(\"The dominant plane is found!!!\")\n",
        "                  print(\"The best distance is \", distance)\n",
        "                  break\n",
        "\n",
        "  # Calculate final homography with the best inliers\n",
        "  #print(np.array(best_inliers1).shape)\n",
        "  inlier_points1 = np.array(best_inliers1).squeeze(1)\n",
        "  inlier_points2 = np.array(best_inliers2).squeeze(1)\n",
        "  final_H = calc_homography(inlier_points1, inlier_points2, len(best_inliers1))\n",
        "  outputs = {\"H\": final_H, \"best_inliers1\": best_inliers1, \"best_inliers2\": best_inliers2}\n",
        "  return outputs\n",
        "\n",
        "def panorama_creation(img1, img2, H):\n",
        "  width = img1.shape[1] + img2.shape[1]\n",
        "  height = img1.shape[0] + img2.shape[0]\n",
        "\n",
        "  result = cv2.warpPerspective(img1, H, (width, height))\n",
        "  result[0:img2.shape[0], 0:img2.shape[1]] = img2\n",
        "\n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.imshow(result)\n",
        "\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  cv2.imwrite(\"out3.jpg\", result)\n",
        "def main():\n",
        "\n",
        "  # Read images\n",
        "  img_path1 = \"/content/drive/MyDrive/3D_Vision_Class/term_project/part1/part1_images4/IMG_4614.JPG\"\n",
        "  img_path2 = \"/content/drive/MyDrive/3D_Vision_Class/term_project/part1/part1_images4/IMG_4615.JPG\"\n",
        "  #img_path1 = \"/content/drive/MyDrive/3D_Vision_Class/term_project/part1/img56.jpg\"\n",
        "  #img_path2 = \"/content/drive/MyDrive/3D_Vision_Class/term_project/part1/img57.jpg\"\n",
        "\n",
        "\n",
        "  # Read masks\n",
        "  img_mask1_pth = \"/content/drive/MyDrive/3D_Vision_Class/term_project/part1/part1_images4/IMG_4614_label.png\"\n",
        "  img_mask2_pth = \"/content/drive/MyDrive/3D_Vision_Class/term_project/part1/part1_images4/IMG_4615_label.png\"\n",
        "\n",
        "  # Read the images\n",
        "  inputs = read_images(img_path1, img_path2, img_mask1_pth, img_mask2_pth)\n",
        "\n",
        "  # Feature detection and matching. If want to use mask, set use_mask=True\n",
        "  src_points, target_points = detect_and_match_features(inputs, use_mask=True)\n",
        "\n",
        "  # Estimate homography by using Normalized DLT with RANSAC\n",
        "  ransac_params = {\"num_iter\": 1000, \"epsilon\": 5, \"threshold\": 0.4, \"num_pnts\": 7}\n",
        "  out = ransac(src_points, target_points, ransac_params)\n",
        "\n",
        "  print(\"Estimated Homography: \", out[\"H\"])\n",
        "  print(\"-----------------------------------------------------------------------\")\n",
        "  print(\"Number of best inlier correspondences: \", len(out[\"best_inliers1\"]))\n",
        "  print(\"-----------------------------------------------------------------------\")\n",
        "\n",
        "  # Test the estimated homography\n",
        "  inlier_points1 = np.array(out[\"best_inliers1\"]).squeeze(1)\n",
        "  inlier_points2 = np.array(out[\"best_inliers2\"]).squeeze(1)\n",
        "  p1 = np.expand_dims(inlier_points1[0], 0)\n",
        "  p1_aug = np.column_stack([p1, np.ones((1,1))]).T\n",
        "  p2 = np.expand_dims(inlier_points2[0], 0)\n",
        "  p2_aug = np.column_stack([p2, np.ones((1,1))]).T\n",
        "  print(\"Distance: \", np.linalg.norm(p2_aug - out[\"H\"].dot(p1_aug))**2)\n",
        "\n",
        "\n",
        "\n",
        "  #### NOTE: SHOULD I CHECK FOR COLLINEARITY OF 3 POINTS ????\n",
        "\n",
        "\n",
        "\n",
        "  # Test the estimated homography by using the opencv function\n",
        "  m, mask = cv2.findHomography(inlier_points1, inlier_points2, cv2.RANSAC, confidence=0.99, ransacReprojThreshold=10.0)\n",
        "  print(\"Opencv homography func distance: \", np.linalg.norm(p2_aug - m.dot(p1_aug)))\n",
        "  #print(\"epsilon_H: \", np.linalg.norm(p2_aug - final_H.dot(p1_aug)))\n",
        "\n",
        "  #img_matches = np.empty((max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], 3), dtype=np.uint8)\n",
        "  #cv2.drawMatches(img1, kp1, img2, kp2, good_matches, img_matches, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "  #cv2_imshow(img_matches)\n",
        "  #cv2.imwrite(\"./matches.png\", img_matches)\n",
        "\n",
        "  #kp_img = cv2.drawKeypoints(img1, kp1, None, color=(0, 255, 0), flags=0)\n",
        "  #cv2_imshow(kp_img)\n",
        "\n",
        "  # Image stitching\n",
        "  img1 = inputs[\"img1\"]\n",
        "  img2 = inputs[\"img2\"]\n",
        "  panorama_creation(img1, img2, out[\"H\"])\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "id": "XwrYXeBeBaFz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}